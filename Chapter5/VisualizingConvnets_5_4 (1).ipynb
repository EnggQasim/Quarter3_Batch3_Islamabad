{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "VisualizingConvnets_5_4.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa4phadsp_LS"
      },
      "source": [
        "# 5.4 Visualizing what convnets learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-WchLOQp_Lf"
      },
      "source": [
        "* Visualizing intermediate convnet outputs (intermediate activations)—Useful for\n",
        "understanding how successive convnet layers transform their input, and for getting a first idea of the meaning of individual convnet filters.\n",
        "* Visualizing convnets filters—Useful for understanding precisely what visual pattern or concept each filter in a convnet is receptive to.\n",
        "* Visualizing heatmaps of class activation in an image—Useful for understanding\n",
        "which parts of an image were identified"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgeDeA-9p_Lg"
      },
      "source": [
        "### 5.4.1 Visualizing intermediate activations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUNPwxfSecN6"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izYOaDZCp_Lg"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/cats_and_dogs_small_1.h5')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHwrPZFEp_Li"
      },
      "source": [
        "#### Listing 5.25 Preprocessing a single image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w18fDpMWp_Li"
      },
      "source": [
        "img_path = '/cat.1.jpg'\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255.\n",
        "# <1> Its shape is (1, 150, 150, 3)\n",
        "print(img_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mizRqtozp_Lj"
      },
      "source": [
        "## Listing 5.26 Displaying the test picture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP--z2Wgp_Lj"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a--Hldxnp_Lj"
      },
      "source": [
        "##### Listing 5.27 Instantiating a model from an input tensor and a list of output tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58KLoVBEp_Lk"
      },
      "source": [
        "from tensorflow.keras import models\n",
        "layer_outputs = [layer.output for layer in model.layers[:8]]\n",
        "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqUV7k5lp_Lk"
      },
      "source": [
        "#### Listing 5.28 Running the model in predict mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFye3-Kwp_Lk"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth=True\n",
        "sess = tf.compat.v1.Session(config=config)\n",
        "\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "import tensorflow as tf\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "sess = tf.compat.v1.Session(config=config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQ8hdF-Wp_Lk"
      },
      "source": [
        "import tensorflow as tf\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwIOe-Lfp_Ll"
      },
      "source": [
        "activations = activation_model.predict(img_tensor)\n",
        "\n",
        "first_layer_activation = activations[0]\n",
        "print(first_layer_activation.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVwkOKDtp_Ll"
      },
      "source": [
        "activation_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW3rU_54p_Ll"
      },
      "source": [
        "#### Listing 5.29 Visualizing the fourth channel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9OM_y6rp_Lm"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.matshow(first_layer_activation[0, :, :, 4], cmap='viridis')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnjJU6SOp_Lm"
      },
      "source": [
        "#### Listing 5.30 Visualizing the seventh channel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NJ62FSGp_Lm"
      },
      "source": [
        "plt.matshow(first_layer_activation[0, :, :, 7], cmap='viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fsdpXrVp_Lm"
      },
      "source": [
        "#### Listing 5.31 Visualizing every channel in every intermediate activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "7C18BqSop_Ln"
      },
      "source": [
        "layer_names = []\n",
        "for layer in model.layers[:8]:\n",
        "    layer_names.append(layer.name)\n",
        "images_per_row = 16\n",
        "for layer_name, layer_activation in zip(layer_names, activations):\n",
        "    n_features = layer_activation.shape[-1]\n",
        "    size = layer_activation.shape[1]\n",
        "    n_cols = n_features // images_per_row\n",
        "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
        "    for col in range(n_cols):\n",
        "        for row in range(images_per_row):\n",
        "            channel_image = layer_activation[0,:, :,\n",
        "                                             col * images_per_row + row]\n",
        "            channel_image -= channel_image.mean()\n",
        "            channel_image /= channel_image.std()\n",
        "            channel_image *= 64\n",
        "            channel_image += 128\n",
        "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
        "            display_grid[col * size : (col + 1) * size,\n",
        "                         row * size : (row + 1) * size] = channel_image\n",
        "    scale = 1. / size\n",
        "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
        "    scale * display_grid.shape[0]))\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3ilGvnQp_Ln"
      },
      "source": [
        "### Listing 5.32 Defining the loss tensor for filter visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJYRlf7jp_Ln"
      },
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "model = VGG16(weights='imagenet',\n",
        "            include_top=False)\n",
        "\n",
        "layer_name = 'block3_conv1'\n",
        "filter_index = 0\n",
        "\n",
        "layer_output = model.get_layer(layer_name).output\n",
        "loss = K.mean(layer_output[:, :, :, filter_index])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8c50I1nV4J3"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GntSA1ewp_Lo"
      },
      "source": [
        "### Listing 5.33 Obtaining the gradient of the loss with regard to the input\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVfHONGOp_Lp"
      },
      "source": [
        "grads = K.gradients(loss, model.input)[0]\r\n",
        "grads"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8pK3MGFgM4p"
      },
      "source": [
        "**Listing 5.34 Gradient-normalization **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEOCcRJ3f0vJ"
      },
      "source": [
        "grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\r\n",
        "grads"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LOkh2hSgYwD"
      },
      "source": [
        "**Listing 5.35 Fetching Numpy output values given Numpy input values**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVLBbScjp_Lp"
      },
      "source": [
        "iterate = K.function([model.input], [loss, grads])\n",
        "import numpy as np\n",
        "loss_value, grads_value = iterate([np.zeros((1, 150, 150, 3))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrGlVvC7ggp3"
      },
      "source": [
        "**Listing 5.36 Loss maximization via stochastic gradient descent**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhaFHEEFgnbc"
      },
      "source": [
        "input_img_data = np.random.random((1, 150, 150, 3)) * 20 + 128.\r\n",
        "step = 1.\r\n",
        "for i in range(40):\r\n",
        "  loss_value, grads_value = iterate([input_img_data])\r\n",
        "  input_img_data += grads_value * step"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH4JRAnLgw3m"
      },
      "source": [
        "**Listing 5.37 Utility function to convert a tensor into a valid image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOOfKk8fgt5I"
      },
      "source": [
        "def deprocess_image(x):\r\n",
        "  x -= x.mean()\r\n",
        "  x /= (x.std() + 1e-5)\r\n",
        "  x *= 0.1\r\n",
        "  x += 0.5\r\n",
        "  x = np.clip(x, 0, 1)\r\n",
        "  x *= 255\r\n",
        "  x = np.clip(x, 0, 255).astype('uint8')\r\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5KZkd5Xg8a2"
      },
      "source": [
        "**Listing 5.38 Function to generate filter visualizations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsGukfsIg3qh"
      },
      "source": [
        "def generate_pattern(layer_name, filter_index, size=150):\r\n",
        "  layer_output = model.get_layer(layer_name).output\r\n",
        "  loss = K.mean(layer_output[:, :, :, filter_index])\r\n",
        "  grads = K.gradients(loss, model.input)[0]\r\n",
        "  grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\r\n",
        "  iterate = K.function([model.input], [loss, grads])\r\n",
        "  input_img_data = np.random.random((1, size, size, 3)) * 20 + 128.\r\n",
        "  step = 1.\r\n",
        "  for i in range(40):\r\n",
        "    loss_value, grads_value = iterate([input_img_data])\r\n",
        "    input_img_data += grads_value * step\r\n",
        "  img = input_img_data[0]\r\n",
        "  return deprocess_image(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnRTNfCHhHuW"
      },
      "source": [
        "plt.imshow(generate_pattern('block3_conv1', 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uWyLrW6hOf5"
      },
      "source": [
        "**Listing 5.39 Generating a grid of all filter response patterns in a layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6t-7OdPpgdVw"
      },
      "source": [
        "layer_name = 'block1_conv1'\r\n",
        "size = 64\r\n",
        "margin = 5\r\n",
        "results = np.zeros((8 * size+7* margin, 8 * size+7* margin, 3))\r\n",
        "\r\n",
        "for i in range(8):\r\n",
        "  for j in range(8):\r\n",
        "    filter_img = generate_pattern(layer_name, i + (j * 8), size=size)\r\n",
        "    horizontal_start = i * size + i * margin\r\n",
        "    horizontal_end = horizontal_start + size\r\n",
        "    vertical_start = j * size + j * margin\r\n",
        "    vertical_end = vertical_start + size\r\n",
        "    results[horizontal_start: horizontal_end,\r\n",
        "            vertical_start: vertical_end, :] = filter_img\r\n",
        "plt.figure(figsize=(20, 20))\r\n",
        "plt.imshow(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB1D0-3fh0s2"
      },
      "source": [
        "**5.4.3 Visualizing heatmaps of class activation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trTI5fgkp_Lp"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\r\n",
        "model = VGG16(weights='imagenet')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szREZrc2h4OO"
      },
      "source": [
        "img_path = '/content/abc.jpg'\r\n",
        "img = image.load_img(img_path, target_size=(224, 224))\r\n",
        "from keras.preprocessing import image\r\n",
        "from keras.applications.vgg16 import preprocess_input, decode_predictions\r\n",
        "import numpy as np\r\n",
        "x = image.img_to_array(img)\r\n",
        "x = np.expand_dims(x, axis=0)\r\n",
        "x = preprocess_input(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYlPeuSgh8tK"
      },
      "source": [
        " preds = model.predict(x)\r\n",
        " print('Predicted:', decode_predictions(preds, top=3)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0NfPu_CiA5B"
      },
      "source": [
        "np.argmax(preds[0])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7Jfeo6gieDF"
      },
      "source": [
        "**Listing 5.42 Setting up the Grad-CAM algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5Vnfibwibyx"
      },
      "source": [
        "african_e66lephant_output = model.output[:, 386]\r\n",
        "last_conv_layer = model.get_layer('block5_conv3')\r\n",
        "\r\n",
        "grads = K.gradients(african_e66lephant_output, last_conv_layer.output)[0]\r\n",
        "pooled_grads = K.mean(grads, axis=(0, 1, 2))\r\n",
        "iterate = K.function([model.input],\r\n",
        "                     [pooled_grads, last_conv_layer.output[0]])\r\n",
        "\r\n",
        "pooled_grads_value, conv_layer_output_value = iterate([x])\r\n",
        "for i in range(512):\r\n",
        "  conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\r\n",
        "heatmap = np.mean(conv_layer_output_value, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k5yWVmhi8Lt"
      },
      "source": [
        "**Listing 5.43 Heatmap post-processing**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJtTO1QLiqm-"
      },
      "source": [
        "heatmap = np.maximum(heatmap, 0)\r\n",
        "heatmap /= np.max(heatmap)\r\n",
        "plt.matshow(heatmap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKfuTfeXjIJF"
      },
      "source": [
        "**Listing 5.44 Superimposing the heatmap with the original picture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUzZCBsxfEsa"
      },
      "source": [
        "import cv2\r\n",
        "img = cv2.imread(img_path)\r\n",
        "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\r\n",
        "heatmap = np.uint8(255 * heatmap)\r\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\r\n",
        "superimposed_img = heatmap * 0.4 + img\r\n",
        "cv2.imwrite('/content/ab.jpg', superimposed_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpOd2O6HjPFJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}